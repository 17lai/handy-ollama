# 在 Java 中使用 Ollama API

本文介绍了如何在 Java 中使用 Ollama API。这篇文档旨在帮助开发者快速上手并充分利用Ollama的能力。你可以直接在程序中调用 Ollama API，也可以通过 Spring AI 组件调用 Ollama。通过学习本文档，你可以轻松集成 Ollama 到你的项目中。

## 一、 环境准备
在 Java 中使用 Ollama API ，请确保你已经准备好了以下环境和工具：

- **Java Development Kit (JDK)**：安装版本 1.8 或更高版本的 JDK。
- **构建工具**：如 Maven 或 Gradle，用于项目依赖管理。
- **HTTP 客户端库**：选择一个合适的 HTTP 客户端库，如 Apache HttpClient 或 OkHttp。

## 二、 直接使用 Ollama
github上有很多第三方开发的组件，可以很方便地在应用中集成 Ollama，这里以[Asedem](https://github.com/Asedem/OllamaJavaAPI)为例，可按以下 3 个步骤(这里使用 maven 做项目管理)：
1. 在 pom.xml 中增加 ollama 依赖
```xml
<repositories>
    <repository>
        <id>jitpack.io</id>
        <url>https://jitpack.io</url>
    </repository>
</repositories>

<dependencies>
    <dependency>
        <groupId>com.github.Asedem</groupId>
        <artifactId>OllamaJavaAPI</artifactId>
        <version>master-SNAPSHOT</version>
    </dependency>
</dependencies>
```

2. 初始化 Ollama
```java
// 默认情况下，它将连接到 localhost:11434
Ollama ollama = Ollama.initDefault();

// 对于自定义值
Ollama ollama = Ollama.init("http://localhost", 11434);
```
3. 使用 Ollama
* 对话
```java
String model = "llama2:latest"; // 指定模型
String prompt = "为什么天空是蓝色的？"; // 提供提示

GenerationResponse response = ollama.generate(new GenerationRequest(model, prompt));

// 打印生成的响应
System.out.println(response.response());
```

* 列出本地模型
```java
List<Model> models = ollama.listModels(); // 返回 Model 对象的列表
```
* 显示模型信息
```java
ModelInfo modelInfo = ollama.showInfo("llama2:latest"); // 返回 ModelInfo 对象
```

* 复制模型
```java
boolean success = ollama.copy("llama2:latest", "llama2-backup"); // 如果复制过程成功返回 true
```
* 删除模型
```java
boolean success = ollama.delete("llama2-backup"); // 如果删除成功返回 true
```


## 三、 使用 Spring AI 调用 Ollama

### Spring AI 简介
Spring AI是一个专为人工智能工程而设计的应用框架。核心功能如下：
* 跨AI提供商的API支持：Spring AI提供了一套可移植的API，支持与多个AI服务提供商的聊天、文本到图像和嵌入模型进行交云。
* 同步和流式API选项：框架支持同步和流式API，为开发者提供了灵活的交互方式。
* 模型特定功能访问：允许开发者通过配置参数访问特定模型的功能，提供了更细致的控制。

### 使用 Spring AI
1. 在pom.xml中增加Spring AI依赖
```xml
<dependencies>
    <dependency>
        <groupId>io.springboot.ai</groupId>
        <artifactld>spring-ai-ollama-spring-boot-starter</artifactld>
        <version>1.0.3</version>
    </dependency>
</dependencies>
```

2. 在 Spring Boot 应用的配置文件中添加 Spring AI 和 Ollama 的配置。例如：

```properties
spring.ai.ollama.base-url= http://localhost:11434
spring.ai.ollama.chat.model= gemma:2b
```

3. 使用 OllamaChatClient 进行文字生成或者对话：

首先创建一个 Spring Boot 控制器来调用 Ollama API：

```java
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.RequestParam;
import org.springframework.web.bind.annotation.RestController;
import io.springboot.ai.ollama.OllamaChatClient;
import org.springframework.ai.chat.ChatResponse;
import org.springframework.ai.chat.prompt.Prompt;

@RestController
public class OllamaController {

    private final OllamaChatClient chatClient;

    @Autowired
    public OllamaController(OllamaChatClient chatClient) {
        this.chatClient = chatClient;
    }

    @GetMapping("/ai/getMsg")
    public ChatResponse getOllame(@RequestParam(value = "msg") String msg) {
        Prompt prompt = new Prompt(msg);
        return chatClient.call(prompt);
    }

    @GetMapping("/ai/stream/getMsg")
    public Object getOllameByStream(@RequestParam(value = "msg") String msg) {
        // 流式调用示例，返回一个Flux对象
        return chatClient.stream(new Prompt(msg));
    }
}
```

最后，实现 `OllamaChatClient` 的逻辑，这通常在 service 层中完成：

```java
import org.springframework.stereotype.Service;
import io.springboot.ai.ollama.OllamaChatClient;
import org.springframework.ai.chat.ChatResponse;
import org.springframework.ai.chat.prompt.Prompt;

@Service
public class OllamaService {

    private final OllamaChatClient chatClient;

    public OllamaService(OllamaChatClient chatClient) {
        this.chatClient = chatClient;
    }

    public ChatResponse getResponse(String message) {
        Prompt prompt = new Prompt(message);
        return chatClient.call(prompt);
    }

    public Object getResponseByStream(String message) {
        // 流式响应示例，具体实现可能需要根据实际API调整
        return chatClient.stream(new Prompt(message));
    }
}
```





> 参考文档
* [Spring AI](https://docs.spring.io/spring-ai/docs/current/reference/html/)
* [Ollama Java API](https://github.com/Asedem/OllamaJavaAPI)
* [博客](https://blog.csdn.net/weixin_54925172/article/details/138815936)


