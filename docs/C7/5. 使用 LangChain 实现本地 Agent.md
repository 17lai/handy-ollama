# 使用 LangChain 实现本地 Agent

## 简介


ReAct（Reasoning and Acting）是一种将推理与行动相结合的框架，用于增强智能体在复杂任务中的表现。该框架通过将逻辑推理与实际行动紧密结合，使智能体能够在动态环境中更有效地完成任务。

![](../images/C7-5-1.png)

来源于论文：[ReAct: Synergizing Reasoning and Acting in Language Models](https://arxiv.org/abs/2210.03629)

本文档介绍了如何使用 ReAct 框架在 Ollama 中实现本地代理（Agent）。通过结合 Ollama 的功能与 ReAct 的灵活性，用户能够在本地环境中创建一个高效的交互式代理。此实现能够处理复杂任务，支持多种交互模式，并且优化了任务自动化和用户体验，适合需要高实时性的本地应用场景。

>注: 本文档包含核心代码片段和详细解释。完整代码可见 [notebook](https://github.com/AXYZdong/handy-ollama/blob/main/notebook/C7/LangChain_Agent/%E4%BD%BF%E7%94%A8LangChain%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0Agent.ipynb) 。

## 1. 导入依赖

```python
from langchain_core.tools import tool  
from langchain.pydantic_v1 import BaseModel, Field
from langchain_core.tools import render_text_description
from langchain.agents import AgentExecutor, create_react_agent
from langchain import hub
from langchain_community.chat_models import ChatOllama
```

## 2. 初始化 Agent 工具

定义 `SearchInput` 类继承 `BaseModel`，用于定义输入数据的模式。

`@tool(args_schema=SearchInput)` 使用工具装饰器装饰 `weather_forecast` 函数，并指定其输入模式为 `SearchInput`。


```python
class SearchInput(BaseModel):
    location: str = Field(description="location to search for")  # 定义一个 Pydantic 模型，用于描述输入模式，并提供描述信息

@tool(args_schema=SearchInput)
def weather_forecast(location: str):
    """天气预报工具。"""
    print(f"Weather for {location}")  # 打印要预报天气的位置
    return f"A dummy forecast for {location}"  # 返回给定位置的虚拟天气预报
```

## 3. 本地运行

在本例中使用 `gemma:2b` 模型，对于不同类型的模型，输出结果可能会很不一样（随机性比较大）。

```python
llm = ChatOllama(model="gemma:2b")  # 初始化 ChatOllama 模型，使用 "gemma:2b"
tools = [weather_forecast]  # 使用 weather_forecast 工具
prompt = hub.pull("hwchase17/react-json")  # 从 hub 拉取特定提示
prompt = prompt.partial(
    tools=render_text_description(tools),  # 为提示呈现工具的文本描述
    tool_names=", ".join([t.name for t in tools]),  # 将工具名称连接成一个以逗号分隔的字符串
)
agent = create_react_agent(llm, tools, prompt)  # 使用 llm、工具和自定义提示创建代理
agent_executor = AgentExecutor(agent=agent, tools=tools, handle_parsing_errors=True, verbose=False, format="json")  # 使用指定参数初始化 AgentExecutor
print(agent_executor.invoke({"input":"What is the weather in Paris?"}))  # 使用测试输入调用代理并打印结果
```

## 使用对话历史

在使用对话历史时，需要使用 `react-chat` Prompt 模板。在 invoke 时，加入 `chat_history`。

```python
# 拉去特定提示，注意此处使用的是 react-chat
prompt = hub.pull("hwchase17/react-chat")

# 构建 ReAct agent
agent_history = create_react_agent(llm, tools, prompt)
agent_executor = AgentExecutor(agent=agent_history, tools=tools, verbose=False)

agent_executor.invoke(
    {
        "input": "what's my name? Only use a tool if needed, otherwise respond with Final Answer",
        "chat_history": "Human: Hi! My name is Bob\nAI: Hello Bob! Nice to meet you",
    }
)
```


参考资料

[1] https://react-lm.github.io/

[2] https://python.langchain.com/v0.1/docs/modules/agents/agent_types/react/