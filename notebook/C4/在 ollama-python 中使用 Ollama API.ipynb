{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cf162b3",
   "metadata": {},
   "source": [
    "# 在 ollama-python 中使用 Ollama API\n",
    "> 编者按：推荐使用官方库[ollama](2.%E5%9C%A8%20Python%20%E4%B8%AD%E4%BD%BF%E7%94%A8%20Ollama%20API.md)\n",
    "## 一、 环境准备\n",
    "在开始使用 Python 与 Ollama API 交互之前，请确保您的开发环境满足以下条件：\n",
    "\n",
    "* Python: 安装 Python 3.9 或更高版本。\n",
    "* pip: 确保已安装 pip，Python 的包管理工具。\n",
    "* ollama-python 库: 用于更方便地与 Ollama API 交互。安装命令如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc09948",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "pip install ollama-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da59e042",
   "metadata": {},
   "source": [
    "## 二、 基本请求示例\n",
    "以下是一个使用 Python 发送请求到 Ollama API 的基本示例。\n",
    "### 对话"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "184539e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Response: The sky appears blue to us because of a phenomenon called Rayleigh scattering. Here's why:\n",
      "\n",
      "1. **Light from the sun**: When sunlight enters Earth's atmosphere, it contains all the colors of the visible spectrum (red, orange, yellow, green, blue, indigo, and violet).\n",
      "2. **Scattering by tiny particles**: As sunlight travels through the atmosphere, it encounters tiny molecules of gases such as nitrogen and oxygen. These molecules are much smaller than the wavelength of light.\n",
      "3. **Rayleigh scattering**: The small gas molecules scatter the shorter (blue) wavelengths of light more efficiently than the longer (red) wavelengths. This is known as Rayleigh scattering, named after the British physicist Lord Rayleigh who first described it in 1871.\n",
      "4. **Blue light dominates**: As a result of this scattering, the blue light is distributed throughout the atmosphere and reaches our eyes from all directions. Our brains then interpret this scattered blue light as the color of the sky.\n",
      "\n",
      "In essence, the sky appears blue because the shorter wavelengths (blue) are more easily scattered by the tiny molecules in the atmosphere, making them more visible to us than the longer wavelengths (red).\n",
      "\n",
      "Now, you might be wondering about the red and orange hues that appear during sunrise and sunset. That's a different story! The colors of the sky at these times are influenced by other factors, such as:\n",
      "\n",
      "* **Dust particles**: Larger dust particles in the atmosphere can scatter light in all directions, making the sun appear more reddish.\n",
      "* **Clouds**: Clouds can absorb or scatter certain wavelengths of light, affecting the apparent color of the sky.\n",
      "* **Atmospheric conditions**: Temperature and humidity variations can influence the scattering and absorption of light, leading to changes in the sky's color.\n",
      "\n",
      "So, that's why the sky appears blue during most of the day. Would you like to know more about this topic?\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Ollama API 的基础 URL\n",
    "api_base_url = \"http://localhost:11434/api/generate\"\n",
    "\n",
    "# 准备请求数据\n",
    "data = {\n",
    "    \"model\": \"llama3.1\",  # 指定模型名称\n",
    "    \"prompt\": \"Why is the sky blue?\"  # 提供的提示\n",
    "}\n",
    "\n",
    "try:\n",
    "    # 发送 POST 请求\n",
    "    response = requests.post(api_base_url, json=data)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        full_response = \"\"\n",
    "        for line in response.text.splitlines():\n",
    "            try:\n",
    "                completion = json.loads(line)\n",
    "                # 累积响应片段\n",
    "                full_response += completion[\"response\"]\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(\"Failed to decode JSON on this line:\", line, e)\n",
    "        \n",
    "        # 打印完整的响应\n",
    "        print(\"Full Response:\", full_response)\n",
    "    else:\n",
    "        print(\"Failed to get response. Status code:\", response.status_code)\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(\"An error occurred:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8328425",
   "metadata": {},
   "source": [
    "### 2.1 流式响应处理\n",
    "如果 API 配置为流式响应，你可能需要处理多个响应对象。以下是一个处理流式响应的示例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2cb5c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:55.499757919Z', 'response': 'The', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:55.52316723Z', 'response': ' sky', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:55.545883446Z', 'response': ' appears', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:55.569970608Z', 'response': ' blue', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:55.592916838Z', 'response': ' to', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:55.61617839Z', 'response': ' us', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:55.639182112Z', 'response': ' because', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:55.661647692Z', 'response': ' of', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:55.685773063Z', 'response': ' a', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:55.710297136Z', 'response': ' phenomenon', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:55.736197051Z', 'response': ' called', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:55.760107835Z', 'response': ' scattering', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:55.784245946Z', 'response': ',', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:55.80761293Z', 'response': ' which', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:55.829931834Z', 'response': ' occurs', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:55.854217308Z', 'response': ' when', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:55.877203387Z', 'response': ' sunlight', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:55.901156505Z', 'response': ' interacts', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:55.923437691Z', 'response': ' with', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:55.945571501Z', 'response': ' the', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:55.969151473Z', 'response': ' tiny', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:55.991787036Z', 'response': ' molecules', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:56.014146722Z', 'response': ' of', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:56.037412485Z', 'response': ' gases', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:56.05988888Z', 'response': ' in', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:56.083019904Z', 'response': ' the', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:56.106932417Z', 'response': ' Earth', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:56.129830608Z', 'response': \"'s\", 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:56.153826733Z', 'response': ' atmosphere', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:56.177660711Z', 'response': '.', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:56.201802753Z', 'response': ' Here', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:56.224327142Z', 'response': \"'s\", 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:56.247211533Z', 'response': ' a', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:56.2702343Z', 'response': ' simplified', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:56.292432163Z', 'response': ' explanation', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:56.315839867Z', 'response': ':\\n\\n', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:56.338003777Z', 'response': '1', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:56.360401052Z', 'response': '.', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:56.3847201Z', 'response': ' **', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:56.407416294Z', 'response': 'Sun', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:56.430370864Z', 'response': 'light', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:56.454633893Z', 'response': ' enters', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:56.477388406Z', 'response': ' the', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:56.501139138Z', 'response': ' atmosphere', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:56.523791833Z', 'response': '**:', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:56.546531102Z', 'response': ' When', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:56.570835382Z', 'response': ' sunlight', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:56.593694414Z', 'response': ' enters', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:56.616695225Z', 'response': ' our', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:56.639981797Z', 'response': ' atmosphere', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:56.66274813Z', 'response': ',', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:56.686458946Z', 'response': ' it', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:56.709791144Z', 'response': ' contains', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:56.732439249Z', 'response': ' all', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:56.75543337Z', 'response': ' the', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:56.779746189Z', 'response': ' colors', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:56.80385701Z', 'response': ' of', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:56.827828427Z', 'response': ' the', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:56.852992062Z', 'response': ' visible', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:56.876090412Z', 'response': ' spectrum', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:56.899481504Z', 'response': ' (', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:56.92333422Z', 'response': 'red', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:56.946025767Z', 'response': ',', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:56.96987129Z', 'response': ' orange', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:56.992472125Z', 'response': ',', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:57.014752897Z', 'response': ' yellow', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:57.037960004Z', 'response': ',', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:57.060733702Z', 'response': ' green', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:57.083771743Z', 'response': ',', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:57.106541474Z', 'response': ' blue', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:57.129207415Z', 'response': ',', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:57.153354918Z', 'response': ' ind', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:57.178395936Z', 'response': 'igo', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:57.202650223Z', 'response': ',', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:57.226473331Z', 'response': ' and', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:57.250237115Z', 'response': ' violet', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:57.272911034Z', 'response': ').\\n', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:57.295444539Z', 'response': '2', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:57.319423966Z', 'response': '.', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:57.341723358Z', 'response': ' **', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:57.364310153Z', 'response': 'Light', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:57.387890177Z', 'response': ' scattering', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:57.410230883Z', 'response': ' occurs', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:57.432745232Z', 'response': '**:', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:57.455992336Z', 'response': ' The', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:57.478909068Z', 'response': ' tiny', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:57.503341243Z', 'response': ' molecules', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:57.526656052Z', 'response': ' of', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:57.549940006Z', 'response': ' gases', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:57.574061283Z', 'response': ' like', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:57.596622059Z', 'response': ' nitrogen', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:57.620233895Z', 'response': ' (', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:57.643124278Z', 'response': 'N', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:57.665769181Z', 'response': '2', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:57.688312365Z', 'response': ')', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:57.711197846Z', 'response': ' and', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:57.733882628Z', 'response': ' oxygen', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:57.756490025Z', 'response': ' (', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:57.779716513Z', 'response': 'O', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:57.803272448Z', 'response': '2', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:57.826580936Z', 'response': ')', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:57.849226175Z', 'response': ' in', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:57.874239574Z', 'response': ' the', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:57.898423828Z', 'response': ' air', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:57.923312474Z', 'response': ' scatter', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:57.945922641Z', 'response': ' the', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:57.969469353Z', 'response': ' light', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:57.991425935Z', 'response': ' in', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:58.013081937Z', 'response': ' all', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:58.034733043Z', 'response': ' directions', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:58.056357162Z', 'response': '.', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:58.078295051Z', 'response': ' This', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:58.099899205Z', 'response': ' is', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:58.122486446Z', 'response': ' known', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:58.146146478Z', 'response': ' as', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:58.171423546Z', 'response': ' Ray', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:58.195199239Z', 'response': 'leigh', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:58.218031096Z', 'response': ' scattering', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:58.241222876Z', 'response': '.\\n', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:58.263330437Z', 'response': '3', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:58.286753083Z', 'response': '.', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:58.311122411Z', 'response': ' **', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:58.334034653Z', 'response': 'Short', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:58.356359364Z', 'response': 'er', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:58.380157839Z', 'response': ' wavelengths', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:58.404164959Z', 'response': ' are', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:58.427075486Z', 'response': ' scattered', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:58.450982621Z', 'response': ' more', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:58.474607518Z', 'response': '**:', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:58.498121623Z', 'response': ' The', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:58.523011374Z', 'response': ' shorter', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:58.546077837Z', 'response': ' wavelengths', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:58.570548793Z', 'response': ' of', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:58.594181185Z', 'response': ' light', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:58.617588775Z', 'response': ',', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:58.642102579Z', 'response': ' such', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:58.665539412Z', 'response': ' as', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:58.68995259Z', 'response': ' blue', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:58.716225586Z', 'response': ' and', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:58.740374832Z', 'response': ' violet', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:58.763099955Z', 'response': ',', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:58.787707059Z', 'response': ' are', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:58.810425342Z', 'response': ' scattered', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:58.83341963Z', 'response': ' more', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:58.858135792Z', 'response': ' than', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:58.881688712Z', 'response': ' the', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:58.906404411Z', 'response': ' longer', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:58.929496421Z', 'response': ' wavelengths', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:58.953350744Z', 'response': ',', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:58.976803901Z', 'response': ' like', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:58.999556131Z', 'response': ' red', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:59.023668799Z', 'response': ' and', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:59.047088835Z', 'response': ' orange', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:59.071265174Z', 'response': '.', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:59.094274067Z', 'response': ' This', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:59.11803536Z', 'response': ' is', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:59.141694084Z', 'response': ' because', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:59.164944911Z', 'response': ' the', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:59.18967543Z', 'response': ' smaller', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:59.212753398Z', 'response': ' molecules', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:59.236283662Z', 'response': ' can', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:59.259159935Z', 'response': ' easily', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:59.281760421Z', 'response': ' scatter', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:59.30569577Z', 'response': ' these', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:59.329113653Z', 'response': ' shorter', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:59.352603808Z', 'response': ' wavelengths', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:59.376448608Z', 'response': '.\\n', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:59.399267178Z', 'response': '4', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:59.422826739Z', 'response': '.', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:59.446217254Z', 'response': ' **', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:59.469414602Z', 'response': 'Our', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:59.491768128Z', 'response': ' eyes', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:59.51490769Z', 'response': ' see', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:59.538864747Z', 'response': ' the', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:59.561921272Z', 'response': ' blue', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:59.585678972Z', 'response': ' light', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:59.608381374Z', 'response': '**:', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:59.631285321Z', 'response': ' As', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:59.655418968Z', 'response': ' a', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:59.678125019Z', 'response': ' result', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:59.700728714Z', 'response': ' of', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:59.724598247Z', 'response': ' this', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:59.747317041Z', 'response': ' scattering', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:59.771917853Z', 'response': ',', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:59.794882068Z', 'response': ' we', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:59.817409966Z', 'response': ' see', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:59.841679427Z', 'response': ' the', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:59.864646423Z', 'response': ' blue', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:59.889533652Z', 'response': ' light', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:59.912875062Z', 'response': ' being', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:59.935779084Z', 'response': ' dispersed', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:59.959341111Z', 'response': ' in', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:20:59.982617917Z', 'response': ' all', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:00.00710122Z', 'response': ' directions', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:00.030724208Z', 'response': ',', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:00.055395739Z', 'response': ' giving', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:00.077854206Z', 'response': ' our', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:00.100493955Z', 'response': ' sky', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:00.124208952Z', 'response': ' its', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:00.147137217Z', 'response': ' characteristic', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:00.170195069Z', 'response': ' blue', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:00.193079505Z', 'response': ' color', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:00.215704659Z', 'response': '.\\n\\n', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:00.240093511Z', 'response': 'It', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:00.263059649Z', 'response': \"'s\", 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:00.285906966Z', 'response': ' worth', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:00.309017647Z', 'response': ' noting', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:00.331799475Z', 'response': ' that', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:00.355436322Z', 'response': ':\\n\\n', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:00.378725213Z', 'response': '*', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:00.401280718Z', 'response': ' The', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:00.424948191Z', 'response': ' color', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:00.448079771Z', 'response': ' of', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:00.471671014Z', 'response': ' the', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:00.494669752Z', 'response': ' sky', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:00.517881226Z', 'response': ' changes', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:00.541372153Z', 'response': ' depending', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:00.564091261Z', 'response': ' on', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:00.588228012Z', 'response': ' the', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:00.610832631Z', 'response': ' time', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:00.633399244Z', 'response': ' of', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:00.657380549Z', 'response': ' day', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:00.679821114Z', 'response': ' and', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:00.702451087Z', 'response': ' atmospheric', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:00.726126549Z', 'response': ' conditions', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:00.748861178Z', 'response': '.', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:00.773013855Z', 'response': ' For', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:00.795527525Z', 'response': ' example', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:00.818062032Z', 'response': ':\\n', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:00.84188686Z', 'response': '\\t', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:00.86463955Z', 'response': '+', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:00.88795417Z', 'response': ' During', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:00.911733981Z', 'response': ' sunrise', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:00.934664401Z', 'response': ' and', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:00.958548155Z', 'response': ' sunset', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:00.981770475Z', 'response': ',', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:01.005450899Z', 'response': ' the', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:01.028105044Z', 'response': ' shorter', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:01.051089122Z', 'response': ' wavelengths', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:01.074703846Z', 'response': ' are', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:01.097029917Z', 'response': ' scattered', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:01.120061592Z', 'response': ' away', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:01.142455315Z', 'response': ',', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:01.165070391Z', 'response': ' leaving', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:01.189848915Z', 'response': ' mainly', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:01.212234566Z', 'response': ' longer', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:01.234737232Z', 'response': ' wavelengths', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:01.258539639Z', 'response': ' (', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:01.281034447Z', 'response': 'reds', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:01.30343651Z', 'response': ',', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:01.326695685Z', 'response': ' oranges', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:01.349654928Z', 'response': ')', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:01.373191915Z', 'response': ' to', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:01.395741391Z', 'response': ' reach', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:01.418670281Z', 'response': ' our', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:01.442700841Z', 'response': ' eyes', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:01.46536133Z', 'response': ',', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:01.487965057Z', 'response': ' resulting', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:01.510903827Z', 'response': ' in', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:01.533630694Z', 'response': ' a', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:01.557406357Z', 'response': ' more', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:01.580093191Z', 'response': ' orange', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:01.602227852Z', 'response': '-red', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:01.625863755Z', 'response': ' hue', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:01.649308797Z', 'response': '.\\n', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:01.673052961Z', 'response': '\\t', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:01.695708791Z', 'response': '+', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:01.718582065Z', 'response': ' At', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:01.742145966Z', 'response': ' night', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:01.764821263Z', 'response': ',', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:01.787625884Z', 'response': ' the', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:01.809913111Z', 'response': ' sky', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:01.83267158Z', 'response': ' appears', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:01.857114082Z', 'response': ' darker', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:01.879908652Z', 'response': ' because', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:01.902232642Z', 'response': ' there', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:01.926149433Z', 'response': \"'s\", 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:01.948514864Z', 'response': ' no', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:01.97097265Z', 'response': ' sunlight', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:01.993713524Z', 'response': ' to', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:02.01616246Z', 'response': ' scatter', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:02.039849642Z', 'response': '.\\n\\n', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:02.06293566Z', 'response': 'The', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:02.086144375Z', 'response': ' blue', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:02.109819431Z', 'response': ' color', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:02.13239411Z', 'response': ' of', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:02.155276171Z', 'response': ' the', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:02.179033544Z', 'response': ' sky', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:02.201681579Z', 'response': ' is', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:02.225304049Z', 'response': ' an', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:02.249317656Z', 'response': ' incredible', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:02.273124767Z', 'response': ' phenomenon', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:02.296414589Z', 'response': ' that', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:02.320038534Z', 'response': ' we', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:02.344418933Z', 'response': ' get', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:02.36979373Z', 'response': ' to', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:02.395962425Z', 'response': ' enjoy', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:02.418678661Z', 'response': ' every', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:02.442407779Z', 'response': ' day', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:02.465133997Z', 'response': '.', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:02.487833167Z', 'response': ' Would', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:02.51125549Z', 'response': ' you', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:02.534060807Z', 'response': ' like', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:02.558169325Z', 'response': ' me', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:02.581230694Z', 'response': ' to', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:02.603654112Z', 'response': ' explain', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:02.626977759Z', 'response': ' more', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:02.650116184Z', 'response': ' about', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:02.673647705Z', 'response': ' light', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:02.696380911Z', 'response': ' scattering', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:02.719368016Z', 'response': ' or', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:02.743075078Z', 'response': ' atmospheric', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:02.766123841Z', 'response': ' conditions', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:02.789599107Z', 'response': '?', 'done': False}\n",
      "Partial Response: {'model': 'llama3.1', 'created_at': '2024-08-13T02:21:02.812160751Z', 'response': '', 'done': True, 'done_reason': 'stop', 'context': [128009, 128006, 882, 128007, 271, 10445, 374, 279, 13180, 6437, 30, 128009, 128006, 78191, 128007, 271, 791, 13180, 8111, 6437, 311, 603, 1606, 315, 264, 25885, 2663, 72916, 11, 902, 13980, 994, 40120, 84261, 449, 279, 13987, 35715, 315, 45612, 304, 279, 9420, 596, 16975, 13, 5810, 596, 264, 44899, 16540, 1473, 16, 13, 3146, 31192, 4238, 29933, 279, 16975, 96618, 3277, 40120, 29933, 1057, 16975, 11, 433, 5727, 682, 279, 8146, 315, 279, 9621, 20326, 320, 1171, 11, 19087, 11, 14071, 11, 6307, 11, 6437, 11, 1280, 7992, 11, 323, 80836, 4390, 17, 13, 3146, 14235, 72916, 13980, 96618, 578, 13987, 35715, 315, 45612, 1093, 47503, 320, 45, 17, 8, 323, 24463, 320, 46, 17, 8, 304, 279, 3805, 45577, 279, 3177, 304, 682, 18445, 13, 1115, 374, 3967, 439, 13558, 64069, 72916, 627, 18, 13, 3146, 12755, 261, 93959, 527, 38067, 810, 96618, 578, 24210, 93959, 315, 3177, 11, 1778, 439, 6437, 323, 80836, 11, 527, 38067, 810, 1109, 279, 5129, 93959, 11, 1093, 2579, 323, 19087, 13, 1115, 374, 1606, 279, 9333, 35715, 649, 6847, 45577, 1521, 24210, 93959, 627, 19, 13, 3146, 8140, 6548, 1518, 279, 6437, 3177, 96618, 1666, 264, 1121, 315, 420, 72916, 11, 584, 1518, 279, 6437, 3177, 1694, 77810, 304, 682, 18445, 11, 7231, 1057, 13180, 1202, 29683, 6437, 1933, 382, 2181, 596, 5922, 27401, 430, 1473, 9, 578, 1933, 315, 279, 13180, 4442, 11911, 389, 279, 892, 315, 1938, 323, 45475, 4787, 13, 1789, 3187, 512, 197, 10, 12220, 64919, 323, 44084, 11, 279, 24210, 93959, 527, 38067, 3201, 11, 9564, 14918, 5129, 93959, 320, 54469, 11, 85138, 8, 311, 5662, 1057, 6548, 11, 13239, 304, 264, 810, 19087, 32698, 40140, 627, 197, 10, 2468, 3814, 11, 279, 13180, 8111, 40130, 1606, 1070, 596, 912, 40120, 311, 45577, 382, 791, 6437, 1933, 315, 279, 13180, 374, 459, 15400, 25885, 430, 584, 636, 311, 4774, 1475, 1938, 13, 19418, 499, 1093, 757, 311, 10552, 810, 922, 3177, 72916, 477, 45475, 4787, 30], 'total_duration': 7564875735, 'load_duration': 19140483, 'prompt_eval_count': 17, 'prompt_eval_duration': 185312000, 'eval_count': 315, 'eval_duration': 7312542000}\n"
     ]
    }
   ],
   "source": [
    "from requests.exceptions import StreamConsumedError\n",
    "\n",
    "# 发送请求，并设置 stream 参数为 true 以接收流式响应\n",
    "response = requests.post(api_base_url, json=data, stream=True)\n",
    "\n",
    "try:\n",
    "    # 尝试从响应中读取内容\n",
    "    for line in response.iter_lines():\n",
    "        if line:\n",
    "            # 解析每一行的 JSON 数据\n",
    "            completion_part = json.loads(line.decode())\n",
    "            print(\"Partial Response:\", completion_part)\n",
    "except StreamConsumedError:\n",
    "    print(\"The stream has already been consumed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9ed50e",
   "metadata": {},
   "source": [
    "### 2.2 高级参数\n",
    "Ollama API 支持多种高级参数，我们可以在请求中使用它们来定制模型的行为。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37cee497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: The color of grass being green is due to a combination of biology and chemistry. Here's a brief explanation:\n",
      "\n",
      "**Chlorophyll:** The main reason grass appears green is because of a pigment called chlorophyll, which is present in the cells of plant leaves (including grass blades). Chlorophyll helps plants absorb sunlight, particularly blue light and red light, to undergo photosynthesis – the process by which they convert carbon dioxide and water into glucose (energy) and oxygen. Chlorophyll absorbs blue light and reflects green light, making it visible to our eyes.\n",
      "\n",
      "**Pigment composition:** Grass contains other pigments as well, including carotenoids and anthocyanins. These pigments contribute to the overall color of grass by:\n",
      "\n",
      "* Carotenoids: These yellow-pigmented compounds are present in chloroplasts (the green part of plant cells) and help protect plants from excessive light energy.\n",
      "* Anthocyanins: These purple-pigmented compounds can appear in certain types of plants, like some varieties of grass or flowers. They're responsible for the reddish-blue color we sometimes see on young shoots.\n",
      "\n",
      "**Other factors influencing color:** Other environmental and biological factors can affect the apparent greenness of grass:\n",
      "\n",
      "* Water availability: Drought stress can cause plants to change their pigment composition and become more blue-ish or pale.\n",
      "* Soil quality: Different nutrient levels in the soil can influence plant growth and, consequently, color.\n",
      "* Temperature: Changes in temperature can impact chlorophyll production and, therefore, leaf color.\n",
      "\n",
      "So, in summary, the primary reason grass appears green is due to the presence of chlorophyll, which absorbs certain wavelengths of light and reflects others.\n"
     ]
    }
   ],
   "source": [
    "# 包含高级参数的请求数据\n",
    "data_with_options = {\n",
    "    \"model\": \"llama3.1\",\n",
    "    \"prompt\": \"Why is the grass green?\",\n",
    "    \"options\": {\n",
    "        \"temperature\": 0.9  # 设置温度参数，影响生成文本的随机性\n",
    "    },\n",
    "    \"stream\": False  # 关闭流式响应\n",
    "}\n",
    "\n",
    "# 发送请求\n",
    "response = requests.post(api_base_url, json=data_with_options)\n",
    "\n",
    "# 处理响应\n",
    "if response.ok:\n",
    "    completion = response.json()\n",
    "    print(\"Response:\", completion[\"response\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bdac1b",
   "metadata": {},
   "source": [
    "### 2.3 异常处理\n",
    "在使用 API 时，正确处理可能发生的错误是非常重要的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9da01eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    response = requests.post(api_base_url, json=data)\n",
    "    response.raise_for_status()  # 如果响应状态码不是 200，将抛出异常\n",
    "except requests.exceptions.HTTPError as err:\n",
    "    print(\"HTTP error occurred:\", err)\n",
    "except Exception as err:\n",
    "    print(\"An error occurred:\", err)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d68490",
   "metadata": {},
   "source": [
    "### 2.4 完整工作示例\n",
    "最后，我们可以将所有这些组合在一起，创建一个 Python 脚本，该脚本可以发送请求到 Ollama API 并处理响应。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cda6ab80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'llama3.1', 'created_at': '2024-08-13T02:21:57.267788394Z', 'response': \"The sky appears blue to us because of a phenomenon called Rayleigh scattering, named after the British physicist Lord Rayleigh, who first described it in the late 19th century.\\n\\nHere's what happens:\\n\\n1. **Sunlight**: The sun emits all colors of light (white light), which is made up of a spectrum of colors including red, orange, yellow, green, blue, indigo, and violet.\\n2. **Scattering**: When sunlight enters Earth's atmosphere, it encounters tiny molecules of gases such as nitrogen (N2) and oxygen (O2). These molecules scatter the light in all directions.\\n3. **Short wavelengths scattered more**: The smaller molecules are better at scattering shorter wavelengths of light, which means they scatter blue light more than any other color. This is because blue light has a shorter wavelength than red or orange light, making it more susceptible to being scattered.\\n4. **Blue dominates**: As the scattered blue light travels through the atmosphere, it reaches our eyes from all directions. Since there's so much blue light being scattered, it becomes the dominant color we see in the sky during the daytime.\\n\\nSo, to summarize: The sky appears blue because of the scattering of sunlight by the tiny molecules in the Earth's atmosphere, with shorter wavelengths (like blue) being scattered more than longer wavelengths (like red).\\n\\nOther factors can affect the apparent color of the sky, such as:\\n\\n* **Time of day**: The angle of the sun and the duration of daylight can influence the color.\\n* **Atmospheric conditions**: Pollutants, dust particles, and water vapor in the air can scatter light differently and change the sky's color.\\n* **Clouds and fog**: These can block or absorb sunlight, changing the apparent color of the sky.\\n\\nNow you know why the sky is blue!\", 'done': True, 'done_reason': 'stop', 'context': [128009, 128006, 882, 128007, 271, 10445, 374, 279, 13180, 6437, 30, 128009, 128006, 78191, 128007, 271, 791, 13180, 8111, 6437, 311, 603, 1606, 315, 264, 25885, 2663, 13558, 64069, 72916, 11, 7086, 1306, 279, 8013, 83323, 10425, 13558, 64069, 11, 889, 1176, 7633, 433, 304, 279, 3389, 220, 777, 339, 9478, 382, 8586, 596, 1148, 8741, 1473, 16, 13, 3146, 31192, 4238, 96618, 578, 7160, 73880, 682, 8146, 315, 3177, 320, 5902, 3177, 705, 902, 374, 1903, 709, 315, 264, 20326, 315, 8146, 2737, 2579, 11, 19087, 11, 14071, 11, 6307, 11, 6437, 11, 1280, 7992, 11, 323, 80836, 627, 17, 13, 3146, 3407, 31436, 96618, 3277, 40120, 29933, 9420, 596, 16975, 11, 433, 35006, 13987, 35715, 315, 45612, 1778, 439, 47503, 320, 45, 17, 8, 323, 24463, 320, 46, 17, 570, 4314, 35715, 45577, 279, 3177, 304, 682, 18445, 627, 18, 13, 3146, 12755, 93959, 38067, 810, 96618, 578, 9333, 35715, 527, 2731, 520, 72916, 24210, 93959, 315, 3177, 11, 902, 3445, 814, 45577, 6437, 3177, 810, 1109, 904, 1023, 1933, 13, 1115, 374, 1606, 6437, 3177, 706, 264, 24210, 46406, 1109, 2579, 477, 19087, 3177, 11, 3339, 433, 810, 47281, 311, 1694, 38067, 627, 19, 13, 3146, 10544, 83978, 96618, 1666, 279, 38067, 6437, 3177, 35292, 1555, 279, 16975, 11, 433, 25501, 1057, 6548, 505, 682, 18445, 13, 8876, 1070, 596, 779, 1790, 6437, 3177, 1694, 38067, 11, 433, 9221, 279, 25462, 1933, 584, 1518, 304, 279, 13180, 2391, 279, 62182, 382, 4516, 11, 311, 63179, 25, 578, 13180, 8111, 6437, 1606, 315, 279, 72916, 315, 40120, 555, 279, 13987, 35715, 304, 279, 9420, 596, 16975, 11, 449, 24210, 93959, 320, 4908, 6437, 8, 1694, 38067, 810, 1109, 5129, 93959, 320, 4908, 2579, 3677, 11663, 9547, 649, 7958, 279, 10186, 1933, 315, 279, 13180, 11, 1778, 439, 1473, 9, 3146, 1489, 315, 1938, 96618, 578, 9392, 315, 279, 7160, 323, 279, 8250, 315, 53121, 649, 10383, 279, 1933, 627, 9, 3146, 1688, 8801, 33349, 4787, 96618, 25385, 332, 1821, 11, 16174, 19252, 11, 323, 3090, 38752, 304, 279, 3805, 649, 45577, 3177, 22009, 323, 2349, 279, 13180, 596, 1933, 627, 9, 3146, 16440, 82, 323, 31349, 96618, 4314, 649, 2565, 477, 35406, 40120, 11, 10223, 279, 10186, 1933, 315, 279, 13180, 382, 7184, 499, 1440, 3249, 279, 13180, 374, 6437, 0], 'total_duration': 8789263757, 'load_duration': 10398183, 'prompt_eval_count': 17, 'prompt_eval_duration': 279116000, 'eval_count': 368, 'eval_duration': 8454612000}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "def generate_completion(model, prompt, options=None, stream=False):\n",
    "    url = \"http://localhost:11434/api/generate\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    data = {\"model\": model, \"prompt\": prompt, \"stream\": stream}\n",
    "    if options:\n",
    "        data[\"options\"] = options\n",
    "\n",
    "    try:\n",
    "        response = requests.post(url, json=data, headers=headers, stream=stream)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        if stream:\n",
    "            for line in response.iter_lines():\n",
    "                if line:\n",
    "                    print(json.loads(line.decode()))\n",
    "        else:\n",
    "            return response.json()\n",
    "    \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "# 使用示例\n",
    "if __name__ == \"__main__\":\n",
    "    model_name = \"llama3.1\"\n",
    "    prompt_text = \"Why is the sky blue?\"\n",
    "    completion = generate_completion(model_name, prompt_text)\n",
    "    if completion:\n",
    "        print(completion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c2100d",
   "metadata": {},
   "source": [
    "这个脚本提供了一个基本的框架，你可以根据需要添加更多的功能和错误处理逻辑。希望这个示例能帮助你开始在 Python 中使用 Ollama API。\n",
    "\n",
    "## 三、 使用 ollama-python 库\n",
    "### 3.1 ollama-python 库简介\n",
    "ollama-python 库[（官方文档）](https://pypi.org/project/ollama-python/)提供了与 Ollama API 交互的高级接口，支持以下核心功能：\n",
    "\n",
    "* 模型管理端点: 创建、删除、拉取、推送和列出模型等。\n",
    "* 生成端点: 包括生成和聊天生成端点。\n",
    "* 嵌入端点: 生成给定文本的嵌入。\n",
    "\n",
    "### 3.2 使用OllamaPython 库\n",
    "OllamaPython 库提供了一个更简洁的接口来与 Ollama API 交互。\n",
    "以下是一个使用 `ollama-python` 库的完整 Python 脚本示例：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3fd4132e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Completion for 'Why is the sky blue?': The sky appears blue to us because of a phenomenon called scattering, which occurs when sunlight interacts with the tiny molecules of gases in the atmosphere. Here's a simplified explanation:\n",
      "\n",
      "1. **Sunlight**: The sun emits white light, which contains all the colors of the visible spectrum (red, orange, yellow, green, blue, indigo, and violet).\n",
      "2. **Scattering**: When sunlight enters the Earth's atmosphere, it encounters tiny molecules of gases such as nitrogen (N2) and oxygen (O2). These molecules scatter the light in all directions.\n",
      "3. **Shorter wavelengths scattered more**: The shorter wavelengths of light, like blue and violet, are scattered more than the longer wavelengths, like red and orange. This is because the smaller molecules are more effective at scattering the shorter wavelengths.\n",
      "4. **Blue light dominates**: As a result of this scattering, the blue light becomes the dominant color that reaches our eyes from the sky.\n",
      "\n",
      "There are some additional factors that contribute to the sky appearing blue:\n",
      "\n",
      "* **Clouds and dust particles**: When there are clouds or dust particles in the air, they can scatter the shorter wavelengths of light even more, making the sky appear bluer.\n",
      "* **Time of day**: During sunrise and sunset, the sun's rays have to travel through more of the atmosphere to reach our eyes, which scatters the blue light even more. This is why we often see hues of red, orange, and pink during these times.\n",
      "\n",
      "So, in summary, the sky appears blue because of the scattering of sunlight by the tiny molecules of gases in the atmosphere, which favors shorter wavelengths like blue and violet.\n",
      "\n",
      "Would you like me to elaborate on any specific aspect of this explanation?\n",
      "Local Models:\n",
      "name='llama3.1:latest' digest='91ab477bec9d27086a119e33c471ae7afbd786cc4fbd8f38d8af0a0b949d53aa' size=4661230977 modified_at='2024-08-09T17:49:08.348175042+08:00' details=ModelDetails(format='gguf', family='llama', families=['llama'], parameter_size='8.0B', quantization_level='Q4_0')\n",
      "name='llava:latest' digest='8dd30f6b0cb19f555f2c7a7ebda861449ea2cc76bf1f44e262931f45fc81d081' size=4733363377 modified_at='2024-08-08T14:20:09.31045753+08:00' details=ModelDetails(format='gguf', family='llama', families=['llama', 'clip'], parameter_size='7B', quantization_level='Q4_0')\n",
      "name='glm4xiuxian:latest' digest='348c4463f081b362ef39ef448ff73a1674f9cf55c703de0883c64afbd8cf34c6' size=4661231198 modified_at='2024-08-07T16:16:37.744493536+08:00' details=ModelDetails(format='gguf', family='llama', families=['llama'], parameter_size='8.0B', quantization_level='Q4_0')\n"
     ]
    }
   ],
   "source": [
    "# 引入所需的模块\n",
    "from ollama_python.endpoints import GenerateAPI, ModelManagementAPI\n",
    "import json\n",
    "\n",
    "# 定义函数来初始化 API 客户端\n",
    "def initialize_api_client(base_url, model_name):\n",
    "    # 根据提供的基本信息初始化 GenerateAPI 和 ModelManagementAPI 客户端\n",
    "    generate_api = GenerateAPI(base_url=base_url, model=model_name)\n",
    "    model_management_api = ModelManagementAPI(base_url=base_url)\n",
    "    return generate_api, model_management_api\n",
    "\n",
    "# 主函数\n",
    "def main():\n",
    "    # 设置 API 的基础 URL 和使用的模型名称\n",
    "    base_url = \"http://localhost:11434/api\"\n",
    "    model_name = \"llama3.1\"\n",
    "    \n",
    "    # 初始化 API 客户端\n",
    "    generate_api, model_management_api = initialize_api_client(base_url, model_name)\n",
    "    \n",
    "    # 使用 GenerateAPI 客户端生成文本补全\n",
    "    try:\n",
    "        prompt = \"Why is the sky blue?\"\n",
    "        response = generate_api.generate(prompt=prompt)\n",
    "        print(f\"Generated Completion for '{prompt}': {response.response}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while generating completion: {e}\")\n",
    "    \n",
    "    # 使用 ModelManagementAPI 客户端列出本地模型\n",
    "    try:\n",
    "        models = model_management_api.list_local_models()\n",
    "        print(\"Local Models:\")\n",
    "        for model in models.models:\n",
    "            print(model)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while listing local models: {e}\")\n",
    "\n",
    "# 检查脚本是否作为主程序运行\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d4a371",
   "metadata": {},
   "source": [
    "此脚本展示了如何使用 `ollama-python` 库进行基本操作：\n",
    "\n",
    "1. **初始化 API 客户端**：创建 `GenerateAPI` 和 `ModelManagementAPI` 的实例。\n",
    "2. **生成文本补全**：使用 `GenerateAPI` 来生成给定提示的文本补全。\n",
    "3. **列出本地模型**：使用 `ModelManagementAPI` 来列出所有本地可用的模型。\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 3.3 示例用法\n",
    "1. 补全（生成）\n",
    "- 无流式传输"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "49e9c4ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How are you today? Is there something I can help you with or would you like to chat?'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ollama_python.endpoints import GenerateAPI\n",
    "\n",
    "api = GenerateAPI(base_url=\"http://localhost:11434/api\", model=\"llama3.1\")\n",
    "result = api.generate(prompt=\"Hello World\")\n",
    "result.response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644dbd28",
   "metadata": {},
   "source": [
    "- 流式传输"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b2e12276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "!\n",
      "\n",
      "\n",
      "Is\n",
      " there\n",
      " something\n",
      " I\n",
      " can\n",
      " help\n",
      " you\n",
      " with\n",
      ",\n",
      " or\n",
      " would\n",
      " you\n",
      " like\n",
      " to\n",
      " chat\n",
      "?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ollama_python.endpoints import GenerateAPI\n",
    "\n",
    "# 初始化 GenerateAPI 客户端\n",
    "api = GenerateAPI(base_url=\"http://localhost:11434/api\", model=\"llama3.1\")\n",
    "# 生成文本，使用流式传输\n",
    "for res in api.generate(prompt=\"Hello World\", stream=True):\n",
    "    print(res.response)  # 打印流式响应"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5529d4e",
   "metadata": {},
   "source": [
    "2. 聊天补全\n",
    "* 无流式传输"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96ded017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation error occurred: 2 validation errors for ChatCompletion\n",
      "context\n",
      "  Field required [type=missing, input_value={'model': 'llama3.1', 'cr...al_duration': 640337000}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.8/v/missing\n",
      "message\n",
      "  Input should be a valid list [type=list_type, input_value={'role': 'assistant', 'co...的光线的颜色。'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.8/v/list_type\n"
     ]
    }
   ],
   "source": [
    "from ollama_python.endpoints import GenerateAPI\n",
    "from pydantic import ValidationError\n",
    "\n",
    "# 初始化 GenerateAPI 客户端\n",
    "api = GenerateAPI(base_url=\"http://localhost:11434/api\", model=\"llama3.1\")\n",
    "\n",
    "# 准备聊天消息\n",
    "messages = [{'role': 'user', 'content': '为什么天空是蓝色的？'}]\n",
    "\n",
    "try:\n",
    "    # 尝试生成聊天补全，不使用流式传输\n",
    "    result = api.generate_chat_completion(messages=messages)\n",
    "    print(\"Generated Completion:\", result)\n",
    "\n",
    "except ValidationError as e:\n",
    "    print(f\"Validation error occurred: {e}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef1d75a",
   "metadata": {},
   "source": [
    "* 流式传输\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d80e06d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for StreamChatCompletion\nmessage\n  Input should be a valid list [type=list_type, input_value={'role': 'assistant', 'content': '蓝'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.8/v/list_type",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m messages \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m为什么天空是蓝色的？\u001b[39m\u001b[38;5;124m'\u001b[39m}]\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# 生成聊天补全，使用流式传输\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mres\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_chat_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessage\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 打印流式响应中的聊天消息\u001b[39;00m\n",
      "File \u001b[1;32md:\\Install\\MiniConda\\envs\\ollama\\Lib\\site-packages\\ollama_python\\endpoints\\base.py:41\u001b[0m, in \u001b[0;36mBaseAPI._stream\u001b[1;34m(self, endpoint, parameters, return_type)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m line:\n\u001b[0;32m     40\u001b[0m     resp \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(line)\n\u001b[1;32m---> 41\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[43mreturn_type\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresp\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m return_type \u001b[38;5;28;01melse\u001b[39;00m resp\n",
      "File \u001b[1;32md:\\Install\\MiniConda\\envs\\ollama\\Lib\\site-packages\\pydantic\\main.py:193\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(self, **data)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[0;32m    192\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 193\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValidationError\u001b[0m: 1 validation error for StreamChatCompletion\nmessage\n  Input should be a valid list [type=list_type, input_value={'role': 'assistant', 'content': '蓝'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.8/v/list_type"
     ]
    }
   ],
   "source": [
    "from ollama_python.endpoints import GenerateAPI\n",
    "\n",
    "# 初始化 GenerateAPI 客户端\n",
    "api = GenerateAPI(base_url=\"http://localhost:11434/api\", model=\"llama3.1\")\n",
    "# 准备聊天消息\n",
    "messages = [{'role': 'user', 'content': '为什么天空是蓝色的？'}]\n",
    "# 生成聊天补全，使用流式传输\n",
    "for res in api.generate_chat_completion(messages=messages, stream=True):\n",
    "    print(res.message)  # 打印流式响应中的聊天消息"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a3f0d9",
   "metadata": {},
   "source": [
    "3. 带图片的聊天请求"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6e94df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama_python.endpoints import GenerateAPI\n",
    "\n",
    "# 初始化 GenerateAPI 客户端，使用支持多模态的模型\n",
    "api = GenerateAPI(base_url=\"http://localhost:11434/api\", model=\"llava\")\n",
    "# 准备包含图片的聊天消息\n",
    "messages = [{'role': 'user', 'content': '这张图片里有什么？', 'image': '图片的Base64编码'}]\n",
    "# 生成聊天补全，处理图片\n",
    "result = api.generate_chat_completion(messages=messages)\n",
    "print(result.message)  # 打印包含图片处理结果的聊天消息"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7f3ca1",
   "metadata": {},
   "source": [
    "4. 嵌入（Embeddings Endpoint）\n",
    "* 生成嵌入\n",
    "> 注意：此端点已被 `/api/embed` 取代"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1a547a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama_python.endpoints import EmbeddingAPI\n",
    "\n",
    "# 初始化 EmbeddingAPI 客户端\n",
    "api = EmbeddingAPI(base_url=\"http://localhost:11434/api\", model=\"llama3.1\")\n",
    "# 生成文本嵌入，设置随机种子以复现结果\n",
    "result = api.get_embedding(prompt=\"Hello World\", options={\"seed\": 10})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cd65af",
   "metadata": {},
   "source": [
    "5. 模型管理\n",
    "* 创建模型\n",
    "  \n",
    "无流式传输"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eece9942",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama_python.endpoints import ModelManagementAPI\n",
    "\n",
    "# 初始化 ModelManagementAPI 客户端\n",
    "api = ModelManagementAPI(base_url=\"http://localhost:11434/api\")\n",
    "# 创建模型\n",
    "result = api.create(name=\"test_model\", model_file=\"模型文件路径\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dee8507",
   "metadata": {},
   "source": [
    "流式传输"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971ae8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama_python.endpoints import ModelManagementAPI\n",
    "\n",
    "# 初始化 ModelManagementAPI 客户端\n",
    "api = ModelManagementAPI(base_url=\"http://localhost:11434/api\")\n",
    "# 创建模型，使用流式传输\n",
    "for res in api.create(name=\"test_model\", model_file=\"模型文件路径\", stream=True):\n",
    "    print(res.status)  # 打印创建过程中的状态信息"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fa0fde",
   "metadata": {},
   "source": [
    "* 列出本地模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30f45ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ModelTag(name='llama3.1:latest', digest='91ab477bec9d27086a119e33c471ae7afbd786cc4fbd8f38d8af0a0b949d53aa', size=4661230977, modified_at='2024-08-09T17:49:08.348175042+08:00', details=ModelDetails(format='gguf', family='llama', families=['llama'], parameter_size='8.0B', quantization_level='Q4_0')), ModelTag(name='llava:latest', digest='8dd30f6b0cb19f555f2c7a7ebda861449ea2cc76bf1f44e262931f45fc81d081', size=4733363377, modified_at='2024-08-08T14:20:09.31045753+08:00', details=ModelDetails(format='gguf', family='llama', families=['llama', 'clip'], parameter_size='7B', quantization_level='Q4_0')), ModelTag(name='glm4xiuxian:latest', digest='348c4463f081b362ef39ef448ff73a1674f9cf55c703de0883c64afbd8cf34c6', size=4661231198, modified_at='2024-08-07T16:16:37.744493536+08:00', details=ModelDetails(format='gguf', family='llama', families=['llama'], parameter_size='8.0B', quantization_level='Q4_0'))]\n"
     ]
    }
   ],
   "source": [
    "from ollama_python.endpoints import ModelManagementAPI\n",
    "\n",
    "# 初始化 ModelManagementAPI 客户端\n",
    "api = ModelManagementAPI(base_url=\"http://localhost:11434/api\")\n",
    "# 列出本地模型\n",
    "result = api.list_local_models()\n",
    "print(result.models)  # 打印本地模型列表"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c290fb",
   "metadata": {},
   "source": [
    "* 显示模型信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "baf5d8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "format='gguf' family='llama' families=['llama'] parameter_size='8.0B' quantization_level='Q4_0'\n"
     ]
    }
   ],
   "source": [
    "from ollama_python.endpoints import ModelManagementAPI\n",
    "\n",
    "# 初始化 ModelManagementAPI 客户端\n",
    "api = ModelManagementAPI(base_url=\"http://localhost:11434/api\")\n",
    "# 显示模型信息\n",
    "result = api.show(name=\"llama3.1\")\n",
    "print(result.details)  # 打印模型详细信息"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d89120",
   "metadata": {},
   "source": [
    "* 复制模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfeb9a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama_python.endpoints import ModelManagementAPI\n",
    "\n",
    "# 初始化 ModelManagementAPI 客户端\n",
    "api = ModelManagementAPI(base_url=\"http://localhost:11434/api\")\n",
    "# 复制模型\n",
    "result = api.copy(source=\"原模型名称\", destination=\"复制的目标模型名称\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e557a14c",
   "metadata": {},
   "source": [
    "* 删除模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8737ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama_python.endpoints import ModelManagementAPI\n",
    "\n",
    "# 初始化 ModelManagementAPI 客户端\n",
    "api = ModelManagementAPI(base_url=\"http://localhost:11434/api\")\n",
    "# 删除模型\n",
    "api.delete(name=\"要删除的模型名称\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c124ab03",
   "metadata": {},
   "source": [
    "* 拉取模型 \n",
    "  \n",
    "无流式传输"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9095eab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama_python.endpoints import ModelManagementAPI\n",
    "\n",
    "# 初始化 ModelManagementAPI 客户端\n",
    "api = ModelManagementAPI(base_url=\"http://localhost:11434/api\")\n",
    "# 拉取模型\n",
    "result = api.pull(name=\"模型名称\")\n",
    "print(result.status)  # 打印拉取状态"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7115876",
   "metadata": {},
   "source": [
    "流式传输"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4957e4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama_python.endpoints import ModelManagementAPI\n",
    "\n",
    "# 初始化 ModelManagementAPI 客户端\n",
    "api = ModelManagementAPI(base_url=\"http://localhost:11434/api\")\n",
    "# 拉取模型，使用流式传输\n",
    "for res in api.pull(name=\"模型名称\", stream=True):\n",
    "    print(res.status)  # 打印流式传输中的拉取状态"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c4f4aa",
   "metadata": {},
   "source": [
    "* 推送模型\n",
    "\n",
    "无流式传输"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61303c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama_python.endpoints import ModelManagementAPI\n",
    "\n",
    "# 初始化 ModelManagementAPI 客户端\n",
    "api = ModelManagementAPI(base_url=\"http://localhost:11434/api\")\n",
    "# 推送模型\n",
    "result = api.push(name=\"模型名称\")\n",
    "print(result.status)  # 打印推送状态"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c68d3a",
   "metadata": {},
   "source": [
    "流式传输"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb66e84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama_python.endpoints import ModelManagementAPI\n",
    "\n",
    "# 初始化 ModelManagementAPI 客户端\n",
    "api = ModelManagementAPI(base_url=\"http://localhost:11434/api\")\n",
    "# 推送模型，使用流式传输\n",
    "for res in api.push(name=\"模型名称\", stream=True):\n",
    "    print(res.status)  # 打印流式传输中的推送状态"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233ac6c7",
   "metadata": {},
   "source": [
    "> 参考文档\n",
    "* [ollama-python 库](https://pypi.org/project/ollama-python/)\n",
    "* [Ollama python](https://github.com/ollama/ollama-python)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ollama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
